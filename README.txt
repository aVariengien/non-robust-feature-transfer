
# Non-robust features transfer for a new adversarial attack against neural image
classifiers
### By Alexandre Variengien

This repository contains the code used in the project of the CS-503 course "Visual Intelligence: machines and mind" at EPFL.


### Instruction

This project implement a new adversarial attack again classifiers. The goal is to
make them classify images humans cannot see.

The attack can be directly reproduced on the CIFAR 10 dataset against 3 models in a Colab notebook.

I also included the notebook used to perform the ImageNet dataset. To be run, it need to be next to a folder
called `ImageNet` containing images in folders corresponding to classes.